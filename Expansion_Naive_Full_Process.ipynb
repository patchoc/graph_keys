{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0cf20b",
   "metadata": {},
   "source": [
    "# Imports & global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5adba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run\n",
    "from subprocess import check_output\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "import rdflib_hdt\n",
    "import ast\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3decb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "path_to_datasets_dir = '/Users/paulosh/Desktop/M2/stage_material/datasets/'\n",
    "path_to_sakey = '/Users/paulosh/Desktop/M2/stage_material/sakey/sakey.jar'\n",
    "class_keys = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae6758",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d0e6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms a text file into a dataframe, input: path to the text file\n",
    "def file_to_dataframe(path):\n",
    "    ds = []\n",
    "    with open(path,  'r', encoding='latin-1') as f:\n",
    "        lines = f.readlines()    \n",
    "        for line in lines:\n",
    "            ds.append(np.array(line.split(\".\\n\")[0].split(\"\\t\")))\n",
    "    \n",
    "    ds = pd.DataFrame(ds).dropna()\n",
    "    for i, row in ds.iterrows():    # removing the newline characters\n",
    "        ifor_val = ds[2][i]\n",
    "        if ds[2][i][-1:] == '\\n':\n",
    "            ifor_val = ds[2][i][:-1]\n",
    "        ds.at[i,2] = ifor_val\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae91a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_datasets_dir = '/Users/paulosh/Desktop/M2/stage_material/datasets/'\n",
    "\n",
    "univ = file_to_dataframe(path_to_datasets_dir + 'University/DB_University')\n",
    "muse = file_to_dataframe(path_to_datasets_dir + 'Museum/DB_Museum')\n",
    "book = file_to_dataframe(path_to_datasets_dir + 'Book/DB_Book')\n",
    "moun = file_to_dataframe(path_to_datasets_dir + 'Mountain/DB_Mountain')\n",
    "albu = file_to_dataframe(path_to_datasets_dir + 'Album/DB_Album')\n",
    "scie = file_to_dataframe(path_to_datasets_dir + 'Scientist/DB_Scientist')\n",
    "acto = file_to_dataframe(path_to_datasets_dir + 'Actor/DB_Actor')\n",
    "film = file_to_dataframe(path_to_datasets_dir + 'Film/DB_Film')\n",
    "city = file_to_dataframe(path_to_datasets_dir + 'City/DB_City')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071eee3",
   "metadata": {},
   "source": [
    "# Parsing the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc44e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments: path to the file we need to parse keys of, and nb of exceptions for SAkey\n",
    "# nb of exceptions can be an integer, or a float representing the threshold\n",
    "def compute_keys(dataset1, nb_exceptions):\n",
    "    if type(nb_exceptions) == float:\n",
    "        ds = file_to_dataframe(dataset1)\n",
    "        nb_exceptions = int(nb_exceptions*len(list(set(ds[0].values))))\n",
    "    print('number of exceptions = %s'%nb_exceptions)\n",
    "    res = check_output(f'java -jar %s %s '%(path_to_sakey, dataset1) + str(nb_exceptions) , shell=True)\n",
    "    res = res.decode().split(\": \")[1][:-2]\n",
    "    res = res.split(\"\\n%s-almost keys:\" %(nb_exceptions - 1))\n",
    "    almost_keys = res[1]              \n",
    "    almost_keys_array = []\n",
    "    for i in almost_keys.split(\"], [\"):\n",
    "        splited = re.split(\"[\\[,\\] ]\", i)\n",
    "        almost_keys_array.append([])\n",
    "        for j in splited:\n",
    "            if j != '' and j != 'prop':\n",
    "                almost_keys_array[-1].append(j)\n",
    "    \n",
    "    if [] in almost_keys_array: almost_keys_array.remove([])            \n",
    "    \n",
    "    l = len(almost_keys_array)\n",
    "    if l > 0:           \n",
    "        class_keys[dataset1.split('DB_')[1]] = almost_keys_array\n",
    "        print(\"%i keys found\" %l)\n",
    "    else: print(\"no keys found\")\n",
    "        \n",
    "        \n",
    "def compute_all_keys(k): # input k = the number of exceptions for SAKey\n",
    "    compute_keys(path_to_datasets_dir + 'University/DB_University', k)\n",
    "    compute_keys(path_to_datasets_dir + 'Museum/DB_Museum', k)\n",
    "    compute_keys(path_to_datasets_dir + 'Book/DB_Book', k)\n",
    "    compute_keys(path_to_datasets_dir + 'Mountain/DB_Mountain', k)\n",
    "    compute_keys(path_to_datasets_dir + 'Album/DB_Album', k)\n",
    "    compute_keys(path_to_datasets_dir + 'Scientist/DB_Scientist', k)\n",
    "    compute_keys(path_to_datasets_dir + 'Actor/DB_Actor', k)\n",
    "    compute_keys(path_to_datasets_dir + 'Film/DB_Film', k)\n",
    "    compute_keys(path_to_datasets_dir + 'City/DB_City', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5936fded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of exceptions = 51\n",
      "12 keys found\n",
      "number of exceptions = 9\n",
      "10 keys found\n",
      "number of exceptions = 149\n",
      "14 keys found\n",
      "number of exceptions = 82\n",
      "4 keys found\n",
      "number of exceptions = 425\n",
      "4 keys found\n",
      "number of exceptions = 92\n",
      "11 keys found\n",
      "number of exceptions = 29\n",
      "41 keys found\n",
      "number of exceptions = 410\n",
      "24 keys found\n",
      "number of exceptions = 96\n",
      "73 keys found\n"
     ]
    }
   ],
   "source": [
    "compute_all_keys(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7af539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'University': [['playsfor-inv', 'hasmotto'],\n",
       "  ['playsfor-inv', 'wascreatedonyear'],\n",
       "  ['skos:preflabel', 'graduatedfrom-inv'],\n",
       "  ['created'],\n",
       "  ['playsfor-inv', 'graduatedfrom-inv'],\n",
       "  ['wascreatedonyear', 'hasmotto'],\n",
       "  ['wascreatedonyear', 'graduatedfrom-inv'],\n",
       "  ['skos:preflabel', 'wascreatedonyear'],\n",
       "  ['owns'],\n",
       "  ['wascreatedondate'],\n",
       "  ['hasmotto', 'graduatedfrom-inv'],\n",
       "  ['skos:preflabel', 'playsfor-inv']],\n",
       " 'Museum': [['haslongitude', 'wascreatedonyear'],\n",
       "  ['haslatitude', 'skos:preflabel'],\n",
       "  ['skos:preflabel', 'wascreatedondate'],\n",
       "  ['haslatitude', 'wascreatedonyear'],\n",
       "  ['created-inv'],\n",
       "  ['skos:preflabel', 'wascreatedonyear'],\n",
       "  ['haslongitude', 'wascreatedondate'],\n",
       "  ['islocatedin', 'wascreatedondate'],\n",
       "  ['haslongitude', 'skos:preflabel'],\n",
       "  ['haslatitude', 'wascreatedondate']],\n",
       " 'Book': [['islocatedin', 'skos:preflabel', 'created-inv'],\n",
       "  ['skos:preflabel', 'wascreatedondate'],\n",
       "  ['hasisbn', 'created-inv', 'wascreatedonyear'],\n",
       "  ['skos:preflabel', 'wascreatedonyear'],\n",
       "  ['created-inv', 'wascreatedondate'],\n",
       "  ['haspages', 'skos:preflabel'],\n",
       "  ['haspages', 'hasisbn', 'wascreatedonyear'],\n",
       "  ['haspages', 'wascreatedondate'],\n",
       "  ['haspages', 'created-inv', 'wascreatedonyear'],\n",
       "  ['hasisbn', 'wascreatedondate'],\n",
       "  ['islocatedin', 'hasisbn', 'skos:preflabel'],\n",
       "  ['islocatedin', 'hasisbn', 'wascreatedonyear'],\n",
       "  ['hasisbn', 'skos:preflabel', 'created-inv'],\n",
       "  ['islocatedin', 'haspages', 'hasisbn', 'created-inv']],\n",
       " 'Mountain': [['haslatitude', 'skos:preflabel'],\n",
       "  ['happenedin-inv'],\n",
       "  ['haslatitude', 'haslongitude'],\n",
       "  ['haslongitude', 'skos:preflabel']],\n",
       " 'Album': [['directed-inv'],\n",
       "  ['created-inv', 'skos:preflabel', 'wascreatedondate'],\n",
       "  ['skos:preflabel', 'wascreatedonyear', 'wascreatedondate'],\n",
       "  ['created-inv', 'skos:preflabel', 'wascreatedonyear']],\n",
       " 'Scientist': [['skos:preflabel', 'iscitizenof'],\n",
       "  ['ismarriedto'],\n",
       "  ['haschild-inv'],\n",
       "  ['haschild'],\n",
       "  ['created'],\n",
       "  ['livesin', 'influences'],\n",
       "  ['influences', 'haswonprize'],\n",
       "  ['worksat'],\n",
       "  ['skos:preflabel', 'haswonprize'],\n",
       "  ['livesin', 'skos:preflabel'],\n",
       "  ['skos:preflabel', 'influences']],\n",
       " 'Actor': [['created', 'wasbornondate'],\n",
       "  ['wasbornin', 'diedondate'],\n",
       "  ['ismarriedto'],\n",
       "  ['actedin', 'wasbornondate'],\n",
       "  ['diedin', 'actedin', 'diedonyear'],\n",
       "  ['iscitizenof', 'wasbornondate'],\n",
       "  ['haswonprize', 'diedonyear'],\n",
       "  ['iscitizenof', 'actedin', 'diedonyear'],\n",
       "  ['diedonyear', 'wasbornin', 'wasbornonyear'],\n",
       "  ['haswonprize', 'wasbornonyear'],\n",
       "  ['haschild'],\n",
       "  ['created', 'wasbornin'],\n",
       "  ['diedin', 'actedin', 'wasbornonyear'],\n",
       "  ['influences'],\n",
       "  ['created', 'wasbornonyear'],\n",
       "  ['iscitizenof', 'actedin', 'wasbornonyear'],\n",
       "  ['diedin', 'created'],\n",
       "  ['directed'],\n",
       "  ['diedin', 'diedonyear', 'wasbornonyear'],\n",
       "  ['created', 'haswonprize'],\n",
       "  ['created', 'diedondate'],\n",
       "  ['ismarriedto-inv'],\n",
       "  ['diedin', 'iscitizenof', 'actedin'],\n",
       "  ['actedin', 'diedondate'],\n",
       "  ['created', 'diedonyear'],\n",
       "  ['created', 'iscitizenof'],\n",
       "  ['wasbornonyear', 'diedondate'],\n",
       "  ['wasbornondate', 'diedonyear'],\n",
       "  ['diedin', 'diedondate'],\n",
       "  ['created', 'actedin'],\n",
       "  ['haswonprize', 'wasbornondate'],\n",
       "  ['actedin', 'diedonyear', 'wasbornonyear'],\n",
       "  ['iscitizenof', 'diedondate'],\n",
       "  ['diedin', 'haswonprize'],\n",
       "  ['skos:preflabel'],\n",
       "  ['wasbornondate', 'diedondate'],\n",
       "  ['iscitizenof', 'haswonprize'],\n",
       "  ['haswonprize', 'diedondate'],\n",
       "  ['diedin', 'wasbornondate'],\n",
       "  ['actedin', 'diedonyear', 'wasbornin'],\n",
       "  ['iscitizenof', 'diedonyear', 'wasbornonyear']],\n",
       " 'Film': [['islocatedin', 'skos:preflabel', 'actedin-inv'],\n",
       "  ['islocatedin', 'created-inv', 'skos:preflabel'],\n",
       "  ['skos:preflabel', 'wascreatedondate'],\n",
       "  ['islocatedin', 'created-inv', 'actedin-inv', 'edited-inv'],\n",
       "  ['directed-inv', 'wascreatedonyear', 'wascreatedondate'],\n",
       "  ['islocatedin', 'directed-inv', 'wascreatedondate'],\n",
       "  ['skos:preflabel', 'wascreatedonyear'],\n",
       "  ['created-inv', 'wascreatedondate'],\n",
       "  ['islocatedin', 'wrotemusicfor-inv', 'wascreatedonyear', 'actedin-inv'],\n",
       "  ['created-inv', 'skos:preflabel', 'actedin-inv'],\n",
       "  ['wascreatedondate', 'edited-inv'],\n",
       "  ['wrotemusicfor-inv', 'skos:preflabel'],\n",
       "  ['directed-inv', 'created-inv', 'skos:preflabel'],\n",
       "  ['wrotemusicfor-inv', 'wascreatedonyear', 'edited-inv'],\n",
       "  ['islocatedin', 'wascreatedonyear', 'edited-inv'],\n",
       "  ['islocatedin', 'directed-inv', 'wascreatedonyear'],\n",
       "  ['wascreatedondate', 'actedin-inv'],\n",
       "  ['skos:preflabel', 'edited-inv'],\n",
       "  ['islocatedin', 'wrotemusicfor-inv', 'created-inv', 'edited-inv'],\n",
       "  ['created-inv', 'wascreatedonyear', 'edited-inv'],\n",
       "  ['wrotemusicfor-inv', 'wascreatedondate'],\n",
       "  ['islocatedin', 'directed-inv', 'skos:preflabel'],\n",
       "  ['islocatedin', 'created-inv', 'wascreatedonyear'],\n",
       "  ['wascreatedonyear', 'actedin-inv', 'edited-inv']],\n",
       " 'City': [['hasnumberofpeople', 'haslatitude'],\n",
       "  ['islocatedin', 'hasmotto', 'wascreatedondate'],\n",
       "  ['hasnumberofpeople', 'wascreatedonyear', 'hasmotto'],\n",
       "  ['skos:preflabel', 'hasmotto'],\n",
       "  ['haspopulationdensity', 'islocatedin-inv'],\n",
       "  ['haspopulationdensity', 'skos:preflabel'],\n",
       "  ['haspopulationdensity', 'isleaderof-inv'],\n",
       "  ['hasnumberofpeople', 'skos:preflabel'],\n",
       "  ['wasbornin-inv', 'wascreatedonyear'],\n",
       "  ['hasnumberofpeople', 'isleaderof-inv', 'islocatedin-inv'],\n",
       "  ['haslatitude', 'haspopulationdensity'],\n",
       "  ['haslongitude', 'hasmotto'],\n",
       "  ['livesin-inv', 'hasmotto'],\n",
       "  ['haspopulationdensity', 'diedin-inv'],\n",
       "  ['isleaderof-inv', 'wasbornin-inv'],\n",
       "  ['haspopulationdensity', 'wascreatedondate'],\n",
       "  ['haspopulationdensity', 'wascreatedonyear'],\n",
       "  ['skos:preflabel', 'wasbornin-inv'],\n",
       "  ['livesin-inv', 'wascreatedondate'],\n",
       "  ['hasnumberofpeople', 'wasbornin-inv'],\n",
       "  ['isleaderof-inv', 'islocatedin-inv', 'hasmotto'],\n",
       "  ['diedin-inv', 'livesin-inv', 'islocatedin-inv'],\n",
       "  ['hasnumberofpeople', 'islocatedin-inv', 'hasmotto'],\n",
       "  ['hasnumberofpeople', 'isleaderof-inv', 'hasmotto'],\n",
       "  ['happenedin-inv'],\n",
       "  ['hasnumberofpeople', 'haslongitude'],\n",
       "  ['created-inv'],\n",
       "  ['skos:preflabel', 'livesin-inv'],\n",
       "  ['isleaderof-inv', 'livesin-inv'],\n",
       "  ['hasnumberofpeople', 'livesin-inv'],\n",
       "  ['wasbornin-inv', 'wascreatedondate'],\n",
       "  ['skos:preflabel', 'wascreatedondate'],\n",
       "  ['haslatitude', 'wascreatedonyear'],\n",
       "  ['skos:preflabel', 'wascreatedonyear'],\n",
       "  ['haspopulationdensity', 'wasbornin-inv'],\n",
       "  ['haslongitude', 'isleaderof-inv'],\n",
       "  ['islocatedin', 'diedin-inv', 'livesin-inv'],\n",
       "  ['islocatedin-inv', 'wascreatedonyear', 'hasmotto'],\n",
       "  ['hascapital-inv'],\n",
       "  ['haslatitude', 'diedin-inv'],\n",
       "  ['haslongitude', 'skos:preflabel'],\n",
       "  ['isleaderof-inv', 'wascreatedonyear', 'hasmotto'],\n",
       "  ['haslatitude', 'wascreatedondate'],\n",
       "  ['livesin-inv', 'wascreatedonyear'],\n",
       "  ['diedin-inv', 'wascreatedonyear'],\n",
       "  ['haslatitude', 'skos:preflabel'],\n",
       "  ['haslongitude', 'wascreatedondate'],\n",
       "  ['diedin-inv', 'haslongitude'],\n",
       "  ['haslatitude', 'isleaderof-inv'],\n",
       "  ['haslongitude', 'livesin-inv'],\n",
       "  ['diedin-inv', 'hasmotto'],\n",
       "  ['haspopulationdensity', 'haslongitude'],\n",
       "  ['hasnumberofpeople', 'islocatedin-inv', 'wascreatedonyear'],\n",
       "  ['haslatitude', 'wasbornin-inv'],\n",
       "  ['hasnumberofpeople', 'isleaderof-inv', 'wascreatedonyear'],\n",
       "  ['diedin-inv', 'wascreatedondate'],\n",
       "  ['wasbornin-inv', 'islocatedin-inv', 'hasmotto'],\n",
       "  ['diedin-inv', 'wasbornin-inv', 'livesin-inv'],\n",
       "  ['islocatedin', 'wasbornin-inv', 'hasmotto'],\n",
       "  ['isleaderof-inv', 'islocatedin-inv', 'wascreatedonyear'],\n",
       "  ['skos:preflabel', 'isleaderof-inv'],\n",
       "  ['haslongitude', 'wascreatedonyear'],\n",
       "  ['hasnumberofpeople', 'diedin-inv'],\n",
       "  ['hasnumberofpeople', 'wascreatedondate'],\n",
       "  ['skos:preflabel', 'islocatedin-inv'],\n",
       "  ['haslatitude', 'livesin-inv'],\n",
       "  ['haslatitude', 'hasmotto'],\n",
       "  ['hasnumberofpeople', 'haspopulationdensity', 'hasmotto'],\n",
       "  ['diedin-inv', 'isleaderof-inv'],\n",
       "  ['isleaderof-inv', 'wascreatedondate'],\n",
       "  ['haspopulationdensity', 'livesin-inv'],\n",
       "  ['diedin-inv', 'skos:preflabel'],\n",
       "  ['islocatedin-inv', 'wascreatedondate']]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89372dd6",
   "metadata": {},
   "source": [
    "# Pre-processing & function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d525c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions for treating data-type/object properties\n",
    "\n",
    "def get_values_from_property(dataset, prop):\n",
    "    searchspace = dataset[dataset[1] == prop]\n",
    "    return list(set(searchspace[2].values))\n",
    "\n",
    "\n",
    "def obj_litt(dataset, prop):\n",
    "    obj = 0; litt = 0\n",
    "    vals = get_values_from_property(dataset, prop)\n",
    "    for val in vals:\n",
    "        if val[0] == '\"' or val.isnumeric(): litt+=1\n",
    "        else: obj+=1\n",
    "    return [obj, litt]\n",
    "\n",
    "\n",
    "def extract_obj_properties(dataset):\n",
    "    objects = []; litts = []\n",
    "    props = list(set(dataset[1].values))\n",
    "    for prop in props:\n",
    "        if obj_litt(dataset, prop)[0] != 0: objects.append(prop)\n",
    "        else: litts.append(prop)\n",
    "    return [objects, litts]\n",
    "\n",
    "\n",
    "def compute_support(dataset, prop):\n",
    "    covered = 0; not_covered = 0\n",
    "    subjects = list(set(dataset[0].values))\n",
    "    for sub in subjects:\n",
    "        ss = dataset[dataset[0] == sub]\n",
    "        props = list(set(ss[1].values))\n",
    "        if prop in props: covered+=1\n",
    "        else: not_covered+=1\n",
    "    return round(covered/(covered+not_covered), 3)\n",
    "\n",
    "\n",
    "def compute_discr(dataset, prop):\n",
    "    ss = dataset[dataset[1] == prop]\n",
    "    return len(list(set(ss[2].values)))/len(ss[2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a303660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the full dbpedia dataset\n",
    "dataset = pd.read_pickle('/Users/paulosh/Downloads/dataset_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f36e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University\n",
      "Museum\n",
      "Book\n",
      "Mountain\n",
      "Album\n",
      "Scientist\n",
      "Actor\n",
      "Film\n",
      "City\n"
     ]
    }
   ],
   "source": [
    "# function that gets the range of a property (i.e. what classes that property targets)\n",
    "def get_range(prop, classe):\n",
    "    triples = dataset[dataset[1] == prop] # we select all triples containing this property \n",
    "    triples = triples[triples[0].isin(class_instances[classe])] # among those, the one who have a subject from our class\n",
    "    vals = triples[2].values  # we extract the values of these triples     \n",
    "\n",
    "    ins = dataset[dataset[0].isin(vals)] # we select all the triples that have these IRIs as subjects\n",
    "    ins = ins[ins[1] == 'type'] # then, these subjects who have a type\n",
    "    return list(set(ins[2].values))\n",
    "\n",
    "\n",
    "class_instances = {}\n",
    "\n",
    "for classe in class_keys:\n",
    "    print(classe)\n",
    "    dataset_searchspace = dataset[dataset[1] == 'type']\n",
    "    \n",
    "    dataset_searchspace = dataset_searchspace[dataset_searchspace[2] == classe]\n",
    "    instances = list(set(dataset_searchspace[0].tolist()))  \n",
    "    class_instances[classe] = instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e7773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing, ranking data-type properties per class\n",
    "best_litt_props = {}\n",
    "\n",
    "def preprocess_props(data, target_classes, k, m, n):\n",
    "    for selected_class in target_classes:\n",
    "        \n",
    "        scores = {}\n",
    "        dataset = data[data[2] == selected_class]\n",
    "        vals = list(set(dataset.head(k)[0]))\n",
    "        sub_dataset = data[data[0].isin(vals)]\n",
    "        obj, litt = extract_obj_properties(sub_dataset)\n",
    "        for prop in litt:\n",
    "            #print(prop)\n",
    "            scores[prop] = m*compute_support(sub_dataset, prop) + n*compute_discr(sub_dataset, prop)*(1/(m+n))\n",
    "        scores = dict(sorted(scores.items(), key=lambda item: item[1]))\n",
    "        max_props = []\n",
    "        for i in range(1, len(litt)+1):\n",
    "            max_props.append(list(scores.keys())[-i])\n",
    "        best_litt_props[selected_class] = max_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f314bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 471 ms, total: 1min 4s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_props(dataset, class_keys, 1000, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f751363b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'University': ['skos:preflabel',\n",
       "  'hasmotto',\n",
       "  'wascreatedondate',\n",
       "  'wascreatedonyear'],\n",
       " 'Museum': ['skos:preflabel',\n",
       "  'haslongitude',\n",
       "  'haslatitude',\n",
       "  'wascreatedondate',\n",
       "  'wascreatedonyear'],\n",
       " 'Book': ['skos:preflabel',\n",
       "  'hasisbn',\n",
       "  'haspages',\n",
       "  'wascreatedondate',\n",
       "  'wascreatedonyear'],\n",
       " 'Mountain': ['skos:preflabel', 'haslongitude', 'haslatitude'],\n",
       " 'Album': ['skos:preflabel', 'wascreatedondate', 'wascreatedonyear'],\n",
       " 'Scientist': ['skos:preflabel'],\n",
       " 'Actor': ['skos:preflabel',\n",
       "  'wasbornondate',\n",
       "  'wasbornonyear',\n",
       "  'diedondate',\n",
       "  'diedonyear'],\n",
       " 'Film': ['skos:preflabel', 'wascreatedondate', 'wascreatedonyear'],\n",
       " 'City': ['haslongitude',\n",
       "  'haslatitude',\n",
       "  'skos:preflabel',\n",
       "  'hasnumberofpeople',\n",
       "  'haspopulationdensity',\n",
       "  'wascreatedondate',\n",
       "  'wascreatedonyear',\n",
       "  'hasmotto']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_litt_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abfe1e",
   "metadata": {},
   "source": [
    "# Key Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5668f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_keys = {}\n",
    "\n",
    "def expand_keys(target_classes, k):\n",
    "    for selected_class in target_classes:\n",
    "        print('\\nexpanding the keys of class: ' + selected_class)\n",
    "        current_ds = eval(str(selected_class[:4]).lower())\n",
    "        obj = extract_obj_properties(current_ds)[0]\n",
    "        litt = extract_obj_properties(current_ds)[1]\n",
    "        newkeys = []\n",
    "        for key in class_keys[selected_class]:\n",
    "            flag_newkey = True\n",
    "            newkey = []\n",
    "            for prop in key: # data-type properties\n",
    "                if prop in litt:\n",
    "                    newkey.append(prop)\n",
    "            for prop in key: # object properties\n",
    "                if prop in obj and get_range(prop, selected_class) and get_range(prop, selected_class) != [selected_class]:\n",
    "                    for pointed_type in get_range(prop, selected_class):\n",
    "                        newkey2 = newkey.copy()\n",
    "                        newkey2.append(prop + ': ' + str(pointed_type) + ' -> ' + str(best_litt_props[pointed_type][:k]))\n",
    "                        newkeys.append(newkey2)\n",
    "        exp_keys[selected_class] = newkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce6189af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "expanding the keys of class: University\n",
      "\n",
      "expanding the keys of class: Museum\n",
      "\n",
      "expanding the keys of class: Book\n",
      "\n",
      "expanding the keys of class: Mountain\n",
      "\n",
      "expanding the keys of class: Album\n",
      "\n",
      "expanding the keys of class: Scientist\n",
      "\n",
      "expanding the keys of class: Actor\n",
      "\n",
      "expanding the keys of class: Film\n",
      "\n",
      "expanding the keys of class: City\n"
     ]
    }
   ],
   "source": [
    "expand_keys(class_keys, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "725aed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skos:preflabel', \"graduatedfrom-inv: Scientist -> ['skos:preflabel']\"]\n",
      "['skos:preflabel', \"graduatedfrom-inv: Actor -> ['skos:preflabel', 'wasbornondate', 'wasbornonyear']\"]\n",
      "[\"created: Book -> ['skos:preflabel', 'hasisbn', 'haspages']\"]\n",
      "[\"graduatedfrom-inv: Scientist -> ['skos:preflabel']\"]\n",
      "[\"graduatedfrom-inv: Actor -> ['skos:preflabel', 'wasbornondate', 'wasbornonyear']\"]\n",
      "['wascreatedonyear', \"graduatedfrom-inv: Scientist -> ['skos:preflabel']\"]\n",
      "['wascreatedonyear', \"graduatedfrom-inv: Actor -> ['skos:preflabel', 'wasbornondate', 'wasbornonyear']\"]\n",
      "['hasmotto', \"graduatedfrom-inv: Scientist -> ['skos:preflabel']\"]\n",
      "['hasmotto', \"graduatedfrom-inv: Actor -> ['skos:preflabel', 'wasbornondate', 'wasbornonyear']\"]\n"
     ]
    }
   ],
   "source": [
    "for key in exp_keys['University']:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecf95d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#saving the expanded keys\n",
    "json.dump(exp_keys, open(\"my_exp_keys_threshold_005.json\", 'w' ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
